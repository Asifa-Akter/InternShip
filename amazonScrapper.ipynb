{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrape_the_salsePerson_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seller Name: SUPERBE BEBE®\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Set up Chrome WebDriver with Selenium\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# Navigate to the desired Amazon product page\n",
    "product_url = \"https://www.amazon.it/dp/B0B9HS2YCW\"  # Replace with the desired product URL\n",
    "driver.get(product_url)\n",
    "\n",
    "# Extract the page source after the page is loaded\n",
    "html = driver.page_source\n",
    "\n",
    "# Close the Selenium WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Parse the page source using BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Find the seller name from the Buy Box\n",
    "seller_element = soup.find('a', {'id': 'sellerProfileTriggerId'})\n",
    "\n",
    "if seller_element is not None:\n",
    "    seller_name = seller_element.get_text(strip=True)\n",
    "    print(\"Seller Name:\", seller_name)\n",
    "else:\n",
    "    print(\"Salesperson: Amazon\")\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrape seller name for list of asins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIN: B0B9HS2YCW, Seller Name: SUPERBE BEBE®\n",
      "ASIN: B072J2J6GZ, Seller Name: Amazon\n",
      "ASIN: B07DM7DWJF, Seller Name: ALENYK\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_seller_names(asins):\n",
    "    # Set up Chrome WebDriver with Selenium\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    seller_names = {}\n",
    "\n",
    "    for asin in asins:\n",
    "        # Navigate to the desired Amazon product page\n",
    "        product_url = f\"https://www.amazon.it/dp/{asin}\"  # Use string formatting to replace {asin}\n",
    "        driver.get(product_url)\n",
    "\n",
    "        # Extract the page source after the page is loaded\n",
    "        html = driver.page_source\n",
    "\n",
    "        # Parse the page source using BeautifulSoup\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # Find the seller name from the Buy Box\n",
    "        seller_element = soup.find('a', {'id': 'sellerProfileTriggerId'})\n",
    "\n",
    "        if seller_element is not None:\n",
    "            seller_name = seller_element.get_text(strip=True)\n",
    "            seller_names[asin] = seller_name\n",
    "        else:\n",
    "            seller_names[asin] = \"Amazon\"\n",
    "\n",
    "    # Close the Selenium WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    return seller_names\n",
    "\n",
    "# Example usage\n",
    "asins = ['B0B9HS2YCW', 'B072J2J6GZ', 'B07DM7DWJF']\n",
    "result = get_seller_names(asins)\n",
    "\n",
    "# Print the seller names\n",
    "for asin, seller_name in result.items():\n",
    "    print(f\"ASIN: {asin}, Seller Name: {seller_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrape sellername for asin read from csv and output results in csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_seller_names(asins):\n",
    "    # Set up Chrome WebDriver with Selenium\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    seller_names = {}\n",
    "\n",
    "    for asin in asins:\n",
    "        # Navigate to the desired Amazon product page\n",
    "        product_url = f\"https://www.amazon.it/dp/{asin}\"  # Use string formatting to replace {asin}\n",
    "        driver.get(product_url)\n",
    "\n",
    "        # Extract the page source after the page is loaded\n",
    "        html = driver.page_source\n",
    "\n",
    "        # Parse the page source using BeautifulSoup\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # Find the seller name from the Buy Box\n",
    "        seller_element = soup.find('a', {'id': 'sellerProfileTriggerId'})\n",
    "\n",
    "        if seller_element is not None:\n",
    "            seller_name = seller_element.get_text(strip=True)\n",
    "            seller_names[asin] = seller_name\n",
    "        else:\n",
    "            seller_names[asin] = \"Amazon\"\n",
    "\n",
    "    # Close the Selenium WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    return seller_names\n",
    "\n",
    "# Read ASINs from CSV file\n",
    "def read_asins_from_csv(filename):\n",
    "    asins = []\n",
    "    with open(filename, 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            asins.extend(row)\n",
    "    return asins\n",
    "\n",
    "# Write seller names to CSV file\n",
    "def write_seller_names_to_csv(filename, seller_names):\n",
    "    with open(filename, 'w', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow(['ASIN', 'Seller Name'])\n",
    "        for asin, seller_name in seller_names.items():\n",
    "            csv_writer.writerow([asin, seller_name])\n",
    "\n",
    "# Example usage\n",
    "input_csv = '/Users/asifa/Desktop/Asifa Growers/buyboxMonitor/uniqueInputs.csv'\n",
    "output_csv = '/Users/asifa/Desktop/Asifa Growers/buyboxMonitor/outputnew.csv'\n",
    "asin_column_name = 'ASIN'  # Specify the column name for ASINs in the CSV\n",
    "\n",
    "asins = read_asins_from_csv(input_csv)\n",
    "seller_names = get_seller_names(asins)\n",
    "write_seller_names_to_csv(output_csv, seller_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrape sellername for asin also the availabilty ,and page not found (final code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_seller_names_and_availability(asins):\n",
    "    # Set up Chrome WebDriver with Selenium\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    seller_data = []\n",
    "\n",
    "    for asin in asins:\n",
    "        # Navigate to the desired Amazon product page\n",
    "        product_url = f\"https://www.amazon.it/dp/{asin}\"  # Use string formatting to replace {asin}\n",
    "        driver.get(product_url)\n",
    "\n",
    "        # Extract the page source after the page is loaded\n",
    "        html = driver.page_source\n",
    "\n",
    "        # Parse the page source using BeautifulSoup\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # Find the seller name from the Buy Box\n",
    "        seller_element = soup.find('a', {'id': 'sellerProfileTriggerId'})\n",
    "\n",
    "        \n",
    "\n",
    "        # Find the availability <div> element\n",
    "        availability_div = soup.find('div', {'id': 'availability'})\n",
    "\n",
    "        if availability_div is not None:\n",
    "            # Check if the product is available or not\n",
    "            if \"Non disponibile\" in availability_div.get_text():\n",
    "                availability_status = \"Not Available\"\n",
    "                seller_name =\"none\"\n",
    "            else:\n",
    "                availability_status = \"Available\"\n",
    "                if seller_element is not None:\n",
    "                    seller_name = seller_element.get_text(strip=True)\n",
    "                else:\n",
    "                    seller_name = \"Amazon\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            availability_status = \"Product page not found\"\n",
    "            seller_name=\"none\"\n",
    "\n",
    "        seller_data.append([asin, seller_name, availability_status])\n",
    "\n",
    "    # Close the Selenium WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    return seller_data\n",
    "\n",
    "# Read ASINs from CSV file\n",
    "def read_asins_from_csv(filename):\n",
    "    asins = []\n",
    "    with open(filename, 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            asins.extend(row)\n",
    "    return asins\n",
    "\n",
    "# Write seller names and availability to CSV file\n",
    "def write_seller_names_and_availability_to_csv(filename, seller_data):\n",
    "    with open(filename, 'w', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow(['ASIN', 'Seller Name', 'Availability_of_Product'])\n",
    "        for data in seller_data:\n",
    "            csv_writer.writerow(data)\n",
    "\n",
    "# Example usage\n",
    "input_csv = '/Users/asifa/Desktop/Asifa Growers/buyboxMonitor/uniqueInputs.csv'\n",
    "output_csv = '/Users/asifa/Desktop/Asifa Growers/buyboxMonitor/finalResult.csv'\n",
    "asin_column_name = 'ASIN'  # Specify the column name for ASINs in the CSV\n",
    "\n",
    "asins = read_asins_from_csv(input_csv)\n",
    "seller_data = get_seller_names_and_availability(asins)\n",
    "write_seller_names_and_availability_to_csv(output_csv, seller_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrapping #other_seller,their names and their price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve product details.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_seller_data(asins):\n",
    "    # Set up Chrome WebDriver with Selenium\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    seller_data = {}\n",
    "\n",
    "    for asin in asins:\n",
    "        # Navigate to the desired Amazon product page\n",
    "        product_url = f\"https://www.amazon.it/dp/{asin}\"\n",
    "        driver.get(product_url)\n",
    "\n",
    "        # Extract the page source after the page is loaded\n",
    "        html = driver.page_source\n",
    "\n",
    "        # Parse the page source using BeautifulSoup\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # Find the seller name from the Buy Box\n",
    "        seller_element = soup.find('a', {'id': 'sellerProfileTriggerId'})\n",
    "\n",
    "        if seller_element is not None:\n",
    "            seller_name = seller_element.get_text(strip=True)\n",
    "        else:\n",
    "            seller_name = \"Amazon\"\n",
    "\n",
    "        # Find the number of other sellers\n",
    "        num_other_sellers_element = soup.find('input', {'id': 'aod-total-offer-count'})\n",
    "        num_other_sellers = int(num_other_sellers_element['value']) if num_other_sellers_element else 0\n",
    "\n",
    "        # Find seller names and prices for other sellers\n",
    "        other_sellers_list = []\n",
    "        if num_other_sellers > 0:\n",
    "            other_sellers = soup.find_all('div', {'class': 'aod-offer'})\n",
    "            for seller in other_sellers:\n",
    "                seller_name = seller.find('span', {'class': 'a-offscreen'}).text.strip()\n",
    "                seller_price = seller.find('span', {'class': 'a-price'}).find('span', {'class': 'a-offscreen'}).text.strip()\n",
    "                other_sellers_list.append({\"seller_name\": seller_name, \"price\": seller_price})\n",
    "\n",
    "        seller_data[asin] = {\"seller_name\": seller_name, \"other_sellers\": other_sellers_list}\n",
    "\n",
    "    # Close the Selenium WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    return seller_data\n",
    "\n",
    "# Write seller data to CSV file\n",
    "def write_seller_data_to_csv(filename, seller_data):\n",
    "    with open(filename, 'w', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow(['ASIN', 'Seller Name', 'Number_of_other_sellers', 'Seller List'])\n",
    "        for asin, data in seller_data.items():\n",
    "            seller_name = data[\"seller_name\"]\n",
    "            other_sellers = data[\"other_sellers\"]\n",
    "            num_other_sellers = len(other_sellers)\n",
    "            seller_list = \", \".join([f\"{seller['seller_name']} ({seller['price']})\" for seller in other_sellers])\n",
    "            csv_writer.writerow([asin, seller_name, num_other_sellers, seller_list])\n",
    "\n",
    "# Example usage\n",
    "input_csv = '/Users/asifa/Desktop/Asifa Growers/buyboxMonitor/input2.csv'\n",
    "output_csv = '/Users/asifa/Desktop/Asifa Growers/buyboxMonitor/output2.csv'\n",
    "\n",
    "asins = read_asins_from_csv(input_csv)\n",
    "seller_data = get_seller_data(asins)\n",
    "write_seller_data_to_csv(output_csv, seller_data)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salesperson not found\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrape_the_salsePerson_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seller Name: SUPERBE BEBE®\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Set up Chrome WebDriver with Selenium\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# Navigate to the desired Amazon product page\n",
    "product_url = \"https://www.amazon.it/dp/B0B9HS2YCW\"  # Replace with the desired product URL\n",
    "driver.get(product_url)\n",
    "\n",
    "# Extract the page source after the page is loaded\n",
    "html = driver.page_source\n",
    "\n",
    "# Close the Selenium WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Parse the page source using BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Find the seller name from the Buy Box\n",
    "seller_element = soup.find('a', {'id': 'sellerProfileTriggerId'})\n",
    "\n",
    "if seller_element is not None:\n",
    "    seller_name = seller_element.get_text(strip=True)\n",
    "    print(\"Seller Name:\", seller_name)\n",
    "else:\n",
    "    print(\"Salesperson: Amazon\")\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrape seller name for list of asins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIN: B0B9HS2YCW, Seller Name: SUPERBE BEBE®\n",
      "ASIN: B072J2J6GZ, Seller Name: Amazon\n",
      "ASIN: B07DM7DWJF, Seller Name: ALENYK\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_seller_names(asins):\n",
    "    # Set up Chrome WebDriver with Selenium\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    seller_names = {}\n",
    "\n",
    "    for asin in asins:\n",
    "        # Navigate to the desired Amazon product page\n",
    "        product_url = f\"https://www.amazon.it/dp/{asin}\"  # Use string formatting to replace {asin}\n",
    "        driver.get(product_url)\n",
    "\n",
    "        # Extract the page source after the page is loaded\n",
    "        html = driver.page_source\n",
    "\n",
    "        # Parse the page source using BeautifulSoup\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # Find the seller name from the Buy Box\n",
    "        seller_element = soup.find('a', {'id': 'sellerProfileTriggerId'})\n",
    "\n",
    "        if seller_element is not None:\n",
    "            seller_name = seller_element.get_text(strip=True)\n",
    "            seller_names[asin] = seller_name\n",
    "        else:\n",
    "            seller_names[asin] = \"Amazon\"\n",
    "\n",
    "    # Close the Selenium WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    return seller_names\n",
    "\n",
    "# Example usage\n",
    "asins = ['B0B9HS2YCW', 'B072J2J6GZ', 'B07DM7DWJF']\n",
    "result = get_seller_names(asins)\n",
    "\n",
    "# Print the seller names\n",
    "for asin, seller_name in result.items():\n",
    "    print(f\"ASIN: {asin}, Seller Name: {seller_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrape sellername for asin read from csv and output results in csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_seller_names(asins):\n",
    "    # Set up Chrome WebDriver with Selenium\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    seller_names = {}\n",
    "\n",
    "    for asin in asins:\n",
    "        # Navigate to the desired Amazon product page\n",
    "        product_url = f\"https://www.amazon.it/dp/{asin}\"  # Use string formatting to replace {asin}\n",
    "        driver.get(product_url)\n",
    "\n",
    "        # Extract the page source after the page is loaded\n",
    "        html = driver.page_source\n",
    "\n",
    "        # Parse the page source using BeautifulSoup\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # Find the seller name from the Buy Box\n",
    "        seller_element = soup.find('a', {'id': 'sellerProfileTriggerId'})\n",
    "\n",
    "        if seller_element is not None:\n",
    "            seller_name = seller_element.get_text(strip=True)\n",
    "            seller_names[asin] = seller_name\n",
    "        else:\n",
    "            seller_names[asin] = \"Amazon\"\n",
    "\n",
    "    # Close the Selenium WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    return seller_names\n",
    "\n",
    "# Read ASINs from CSV file\n",
    "def read_asins_from_csv(filename):\n",
    "    asins = []\n",
    "    with open(filename, 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            asins.extend(row)\n",
    "    return asins\n",
    "\n",
    "# Write seller names to CSV file\n",
    "def write_seller_names_to_csv(filename, seller_names):\n",
    "    with open(filename, 'w', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow(['ASIN', 'Seller Name'])\n",
    "        for asin, seller_name in seller_names.items():\n",
    "            csv_writer.writerow([asin, seller_name])\n",
    "\n",
    "# Example usage\n",
    "input_csv = '/Users/asifa/Desktop/Asifa Growers/buyboxMonitor/uniqueInputs.csv'\n",
    "output_csv = '/Users/asifa/Desktop/Asifa Growers/buyboxMonitor/outputnew.csv'\n",
    "asin_column_name = 'ASIN'  # Specify the column name for ASINs in the CSV\n",
    "\n",
    "asins = read_asins_from_csv(input_csv)\n",
    "seller_names = get_seller_names(asins)\n",
    "write_seller_names_to_csv(output_csv, seller_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrape sellername for asin also the availabilty ,and page not found (final code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_seller_names_and_availability(asins):\n",
    "    # Set up Chrome WebDriver with Selenium\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    seller_data = []\n",
    "\n",
    "    for asin in asins:\n",
    "        # Navigate to the desired Amazon product page\n",
    "        product_url = f\"https://www.amazon.it/dp/{asin}\"  # Use string formatting to replace {asin}\n",
    "        driver.get(product_url)\n",
    "\n",
    "        # Extract the page source after the page is loaded\n",
    "        html = driver.page_source\n",
    "\n",
    "        # Parse the page source using BeautifulSoup\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # Find the seller name from the Buy Box\n",
    "        seller_element = soup.find('a', {'id': 'sellerProfileTriggerId'})\n",
    "\n",
    "        \n",
    "\n",
    "        # Find the availability <div> element\n",
    "        availability_div = soup.find('div', {'id': 'availability'})\n",
    "\n",
    "        if availability_div is not None:\n",
    "            # Check if the product is available or not\n",
    "            if \"Non disponibile\" in availability_div.get_text():\n",
    "                availability_status = \"Not Available\"\n",
    "                seller_name =\"none\"\n",
    "            else:\n",
    "                availability_status = \"Available\"\n",
    "                if seller_element is not None:\n",
    "                    seller_name = seller_element.get_text(strip=True)\n",
    "                else:\n",
    "                    seller_name = \"Amazon\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            availability_status = \"Product page not found\"\n",
    "            seller_name=\"none\"\n",
    "\n",
    "        seller_data.append([asin, seller_name, availability_status])\n",
    "\n",
    "    # Close the Selenium WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    return seller_data\n",
    "\n",
    "# Read ASINs from CSV file\n",
    "def read_asins_from_csv(filename):\n",
    "    asins = []\n",
    "    with open(filename, 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            asins.extend(row)\n",
    "    return asins\n",
    "\n",
    "# Write seller names and availability to CSV file\n",
    "def write_seller_names_and_availability_to_csv(filename, seller_data):\n",
    "    with open(filename, 'w', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow(['ASIN', 'Seller Name', 'Availability_of_Product'])\n",
    "        for data in seller_data:\n",
    "            csv_writer.writerow(data)\n",
    "\n",
    "# Example usage\n",
    "input_csv = '/Users/asifa/Desktop/Asifa/buyboxMonitor/ASIN +Watt 21-07.csv'\n",
    "output_csv = '/Users/asifa/Desktop/Asifa/buyboxMonitor/ASIN +Watt 21-07Output.csv'\n",
    "asin_column_name = 'ASIN'  # Specify the column name for ASINs in the CSV\n",
    "\n",
    "asins = read_asins_from_csv(input_csv)\n",
    "seller_data = get_seller_names_and_availability(asins)\n",
    "write_seller_names_and_availability_to_csv(output_csv, seller_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrapping  sellername for asin also the availabilty ,and page not found and the number of resellers (final code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "#functin for getting the number of resellers\n",
    "def get_other_sellers_and_name(asin):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    offerlist_url = f\"https://www.amazon.it/dp/{asin}/ref=olp-opf-redir?aod=1&ie=UTF8&condition=NEW&th=1\"\n",
    "    driver.get(offerlist_url)\n",
    "\n",
    "    html = driver.page_source\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    input_element = soup.find('input', {'id': 'aod-total-offer-count'})\n",
    "    if input_element is not None:\n",
    "        num_other_sellers = int(input_element.get('value', '0'))\n",
    "        \n",
    "    else:\n",
    "        num_other_sellers = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    seller_element = soup.find('a', {'id': 'sellerProfileTriggerId'})\n",
    "    if seller_element is not None:\n",
    "        seller_name = seller_element.get_text(strip=True)\n",
    "    else:\n",
    "        seller_name = \"Amazon\"\n",
    "\n",
    "    return num_other_sellers, seller_name\n",
    "\n",
    "def get_seller_names_and_availability(asins):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    seller_data = []\n",
    "\n",
    "    for asin in asins:\n",
    "        product_url = f\"https://www.amazon.it/dp/{asin}\"\n",
    "        driver.get(product_url)\n",
    "\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        seller_element = soup.find('a', {'id': 'sellerProfileTriggerId'})\n",
    "\n",
    "        availability_div = soup.find('div', {'id': 'availability'})\n",
    "\n",
    "        if availability_div is not None:\n",
    "            if \"Non disponibile\" in availability_div.get_text():\n",
    "                availability_status = \"Not Available\"\n",
    "                seller_name = \"none\"\n",
    "            else:\n",
    "                availability_status = \"Available\"\n",
    "                if seller_element is not None:\n",
    "                    seller_name = seller_element.get_text(strip=True)\n",
    "                else:\n",
    "                    seller_name = \"Amazon\"\n",
    "        else:\n",
    "            availability_status = \"Product page not found\"\n",
    "            seller_name = \"none\"\n",
    "\n",
    "        num_other_sellers, _ = get_other_sellers_and_name(asin)\n",
    "        seller_data.append([asin, seller_name, availability_status, num_other_sellers])\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return seller_data\n",
    "\n",
    "def read_asins_from_csv(filename):\n",
    "    asins = []\n",
    "    with open(filename, 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            asins.extend(row)\n",
    "    return asins\n",
    "\n",
    "def write_seller_names_and_availability_to_csv(filename, seller_data):\n",
    "    with open(filename, 'w', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow(['ASIN', 'Seller Name', 'Availability_of_Product', 'Number_of_resellers'])\n",
    "        for data in seller_data:\n",
    "            csv_writer.writerow(data)\n",
    "\n",
    "# Example usage\n",
    "input_csv = '/Users/asifa/Desktop/Asifa/buyboxMonitor/input2.csv'\n",
    "output_csv = '/Users/asifa/Desktop/Asifa/buyboxMonitor/Output2.csv'\n",
    "\n",
    "asins = read_asins_from_csv(input_csv)\n",
    "seller_data = get_seller_names_and_availability(asins)\n",
    "write_seller_names_and_availability_to_csv(output_csv, seller_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it gives seller name,reseller name,reseller pricce,number of resellers , only problem: price indexes are wrong\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Other Sellers: 7\n",
      "Seller Name: Aloe Store - L'Angolo dell'Aloe\n",
      "Reseller Names and Prices:\n",
      " - Amazon: 43,30 €\n",
      " - risparmia_infarmacia: 38,35 €\n",
      " - Mypharmaclick: 42,80 €\n",
      " - FarmaciaLoreto: 55,00 €\n",
      " - risparmia_infarmacia: 49,66 €\n",
      " - Farmaenne: 58,00 €\n",
      " - Easyfarma | la tua Farmacia Online: 39,48€\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_num_of_reseller_and_names(asin):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    offerlist_url = f\"https://www.amazon.it/dp/{asin}/ref=olp-opf-redir?aod=1&ie=UTF8&condition=NEW&th=1\"\n",
    "    driver.get(offerlist_url)\n",
    "\n",
    "    html = driver.page_source\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    input_element = soup.find('input', {'id': 'aod-total-offer-count'})\n",
    "    if input_element is not None:\n",
    "        num_other_sellers = int(input_element.get('value', '0'))\n",
    "    else:\n",
    "        num_other_sellers = 0\n",
    "\n",
    "    seller_element = soup.find('a', {'id': 'sellerProfileTriggerId'})\n",
    "    if seller_element is not None:\n",
    "        seller_name = seller_element.get_text(strip=True)\n",
    "    else:\n",
    "        seller_name = \"Amazon\"\n",
    "\n",
    "    # Find all the reseller names and prices on the page\n",
    "    offer_list_div = soup.find('div', {'id': 'aod-offer-list'})\n",
    "    if offer_list_div:\n",
    "        reseller_data = []\n",
    "        reseller_elements = offer_list_div.find_all(\n",
    "            lambda tag: (tag.name == 'a' and tag.get('aria-label') == 'Apre una nuova pagina') or\n",
    "                        (tag.name == 'span' and tag.get('aria-label') == 'Amazon. Apre una nuova pagina')\n",
    "        )\n",
    "        prices = []  # List to store prices\n",
    "        for reseller in reseller_elements:\n",
    "            reseller_name = reseller.get_text(strip=True)\n",
    "            # Find the corresponding price element for the current reseller\n",
    "            price_element = reseller.find_next('span', {'class': 'a-offscreen'})\n",
    "            if price_element:\n",
    "                # If price found, update the list of prices\n",
    "                prices.append(price_element.get_text(strip=True))\n",
    "            reseller_data.append((reseller_name, prices[-1]))  # Use the last price from the list\n",
    "\n",
    "    else:\n",
    "        reseller_data = []\n",
    "\n",
    "    return num_other_sellers, seller_name, reseller_data\n",
    "   \n",
    "# Example usage\n",
    "asin = \"B081PV3S3K\"\n",
    "num_sellers, reseller_name, resellers = get_num_of_reseller_and_names(asin)\n",
    "\n",
    "print(f\"Number of Other Sellers: {num_sellers}\")\n",
    "print(f\"Seller Name: {reseller_name}\")\n",
    "print(\"Reseller Names and Prices:\")\n",
    "for reseller, price in resellers:\n",
    "    print(f\" - {reseller}: {price}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modify code for adding two other column resellers_name and their prices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "#functin for getting the number of resellers\n",
    "def get_other_sellers_and_name(asin):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    offerlist_url = f\"https://www.amazon.it/dp/{asin}/ref=olp-opf-redir?aod=1&ie=UTF8&condition=NEW&th=1\"\n",
    "    driver.get(offerlist_url)\n",
    "\n",
    "    html = driver.page_source\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    input_element = soup.find('input', {'id': 'aod-total-offer-count'})\n",
    "    if input_element is not None:\n",
    "        num_other_sellers = int(input_element.get('value', '0'))\n",
    "        \n",
    "    else:\n",
    "        num_other_sellers = 0\n",
    "\n",
    "\n",
    "    # Find all the reseller names on the page\n",
    "    \n",
    "    offer_list_div = soup.find('div', {'id': 'aod-offer-list'})\n",
    "    if offer_list_div:\n",
    "        reseller_data = []\n",
    "        reseller_elements = offer_list_div.find_all(\n",
    "            lambda tag: (tag.name == 'a' and tag.get('aria-label') == 'Apre una nuova pagina') or\n",
    "                        (tag.name == 'span' and tag.get('aria-label') == 'Amazon. Apre una nuova pagina')\n",
    "        )\n",
    "        for reseller in reseller_elements:\n",
    "            reseller_name = reseller.get_text(strip=True)\n",
    "           \n",
    "            reseller_data.append((reseller_name))\n",
    "    else:\n",
    "        reseller_data = []\n",
    "\n",
    "    return num_other_sellers, reseller_data\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "   \n",
    "\n",
    "def get_seller_names_and_availability(asins):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    seller_data = []\n",
    "\n",
    "    for asin in asins:\n",
    "        product_url = f\"https://www.amazon.it/dp/{asin}\"\n",
    "        driver.get(product_url)\n",
    "\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        seller_element = soup.find('a', {'id': 'sellerProfileTriggerId'})\n",
    "\n",
    "        availability_div = soup.find('div', {'id': 'availability'})\n",
    "\n",
    "        if availability_div is not None:\n",
    "            if \"Non disponibile\" in availability_div.get_text():\n",
    "                availability_status = \"Not Available\"\n",
    "                seller_name = \"none\"\n",
    "            else:\n",
    "                availability_status = \"Available\"\n",
    "                if seller_element is not None:\n",
    "                    seller_name = seller_element.get_text(strip=True)\n",
    "                else:\n",
    "                    seller_name = \"Amazon\"\n",
    "        else:\n",
    "            availability_status = \"Product page not found\"\n",
    "            seller_name = \"none\"\n",
    "\n",
    "        num_other_sellers, _ = get_other_sellers_and_name(asin)\n",
    "        seller_data.append([asin, seller_name, availability_status, num_other_sellers])\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return seller_data\n",
    "\n",
    "def read_asins_from_csv(filename):\n",
    "    asins = []\n",
    "    with open(filename, 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            asins.extend(row)\n",
    "    return asins\n",
    "\n",
    "def write_seller_names_and_availability_to_csv(filename, seller_data):\n",
    "    with open(filename, 'w', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow(['ASIN', 'Seller Name', 'Availability_of_Product', 'Number_of_resellers','Reseller_names'])\n",
    "        for data in seller_data:\n",
    "            csv_writer.writerow(data)\n",
    "\n",
    "# Example usage\n",
    "input_csv = '/Users/asifa/Desktop/Asifa/buyboxMonitor/input2.csv'\n",
    "output_csv = '/Users/asifa/Desktop/Asifa/buyboxMonitor/Output2.csv'\n",
    "\n",
    "asins = read_asins_from_csv(input_csv)\n",
    "seller_data = get_seller_names_and_availability(asins)\n",
    "write_seller_names_and_availability_to_csv(output_csv, seller_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scraping seller name,reseller numbers,reseller name,availability (final code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Function for getting the number of resellers and their names\n",
    "def get_other_sellers_and_name(asin):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    offerlist_url = f\"https://www.amazon.it/dp/{asin}/ref=olp-opf-redir?aod=1&ie=UTF8&condition=NEW&th=1\"\n",
    "    driver.get(offerlist_url)\n",
    "\n",
    "    html = driver.page_source\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    input_element = soup.find('input', {'id': 'aod-total-offer-count'})\n",
    "    if input_element is not None:\n",
    "        num_other_sellers = int(input_element.get('value', '0'))\n",
    "    else:\n",
    "        num_other_sellers = 0\n",
    "\n",
    "    # Find all the reseller names on the page\n",
    "    offer_list_div = soup.find('div', {'id': 'aod-offer-list'})\n",
    "    if offer_list_div:\n",
    "        reseller_data = []\n",
    "        reseller_elements = offer_list_div.find_all(\n",
    "            lambda tag: (tag.name == 'a' and tag.get('aria-label') == 'Apre una nuova pagina') or\n",
    "                        (tag.name == 'span' and tag.get('aria-label') == 'Amazon. Apre una nuova pagina')\n",
    "        )\n",
    "        for reseller in reseller_elements:\n",
    "            reseller_name = reseller.get_text(strip=True)\n",
    "            reseller_data.append(reseller_name)\n",
    "    else:\n",
    "        reseller_data = 'No Resellers'\n",
    "\n",
    "    return num_other_sellers, reseller_data\n",
    "\n",
    "\n",
    "def get_seller_names_and_availability(asins):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    seller_data = []\n",
    "\n",
    "    for asin in asins:\n",
    "        product_url = f\"https://www.amazon.it/dp/{asin}\"\n",
    "        driver.get(product_url)\n",
    "\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        seller_element = soup.find('a', {'id': 'sellerProfileTriggerId'})\n",
    "        availability_div = soup.find('div', {'id': 'availability'})\n",
    "\n",
    "        if availability_div is not None:\n",
    "            if \"Non disponibile\" in availability_div.get_text():\n",
    "                availability_status = \"Not Available\"\n",
    "                seller_name = \"none\"\n",
    "            else:\n",
    "                availability_status = \"Available\"\n",
    "                if seller_element is not None:\n",
    "                    seller_name = seller_element.get_text(strip=True)\n",
    "                else:\n",
    "                    seller_name = \"Amazon\"\n",
    "        else:\n",
    "            availability_status = \"Product page not found\"\n",
    "            seller_name = \"none\"\n",
    "\n",
    "        num_other_sellers, reseller_names = get_other_sellers_and_name(asin)\n",
    "        seller_data.append([asin, seller_name, availability_status, num_other_sellers, reseller_names])\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return seller_data\n",
    "\n",
    "def read_asins_from_csv(filename):\n",
    "    asins = []\n",
    "    with open(filename, 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            asins.extend(row)\n",
    "    return asins\n",
    "\n",
    "def write_seller_names_and_availability_to_csv(filename, seller_data):\n",
    "    with open(filename, 'w', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow(['ASIN', 'Seller Name', 'Availability_of_Product', 'Number_of_resellers', 'Reseller_names'])\n",
    "        for data in seller_data:\n",
    "            csv_writer.writerow(data)\n",
    "\n",
    "# Example usage\n",
    "input_csv = '/Users/asifa/Desktop/Asifa/buyboxMonitor/input2.csv'\n",
    "output_csv = '/Users/asifa/Desktop/Asifa/buyboxMonitor/Output2.csv'\n",
    "\n",
    "asins = read_asins_from_csv(input_csv)\n",
    "seller_data = get_seller_names_and_availability(asins)\n",
    "write_seller_names_and_availability_to_csv(output_csv, seller_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modifying the final code for convert array reseller names into list (DONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Function for getting the number of resellers and their names\n",
    "def get_other_sellers_and_name(asin):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    offerlist_url = f\"https://www.amazon.it/dp/{asin}/ref=olp-opf-redir?aod=1&ie=UTF8&condition=NEW&th=1\"\n",
    "    driver.get(offerlist_url)\n",
    "\n",
    "    html = driver.page_source\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    input_element = soup.find('input', {'id': 'aod-total-offer-count'})\n",
    "    if input_element is not None:\n",
    "        num_other_sellers = int(input_element.get('value', '0'))\n",
    "    else:\n",
    "        num_other_sellers = 0\n",
    "\n",
    "    # Find all the reseller names on the page\n",
    "    offer_list_div = soup.find('div', {'id': 'aod-offer-list'})\n",
    "    if offer_list_div:\n",
    "        reseller_data = []\n",
    "        reseller_elements = offer_list_div.find_all(\n",
    "            lambda tag: (tag.name == 'a' and tag.get('aria-label') == 'Apre una nuova pagina') or\n",
    "                        (tag.name == 'span' and tag.get('aria-label') == 'Amazon. Apre una nuova pagina')\n",
    "        )\n",
    "        for reseller in reseller_elements:\n",
    "            reseller_name = reseller.get_text(strip=True)\n",
    "            reseller_data.append(reseller_name)\n",
    "    else:\n",
    "        reseller_data = 'No Resellers'\n",
    "\n",
    "    return num_other_sellers, reseller_data\n",
    "\n",
    "\n",
    "def get_seller_names_and_availability(asins):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    seller_data = []\n",
    "\n",
    "    for asin in asins:\n",
    "        product_url = f\"https://www.amazon.it/dp/{asin}\"\n",
    "        driver.get(product_url)\n",
    "\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        seller_element = soup.find('a', {'id': 'sellerProfileTriggerId'})\n",
    "        availability_div = soup.find('div', {'id': 'availability'})\n",
    "\n",
    "        if availability_div is not None:\n",
    "            if \"Non disponibile\" in availability_div.get_text():\n",
    "                availability_status = \"Not Available\"\n",
    "                seller_name = \"none\"\n",
    "            else:\n",
    "                availability_status = \"Available\"\n",
    "                if seller_element is not None:\n",
    "                    seller_name = seller_element.get_text(strip=True)\n",
    "                else:\n",
    "                    seller_name = \"Amazon\"\n",
    "        else:\n",
    "            availability_status = \"Product page not found\"\n",
    "            seller_name = \"none\"\n",
    "\n",
    "        num_other_sellers, reseller_names = get_other_sellers_and_name(asin)\n",
    "        if num_other_sellers > 0:      \n",
    "            resellers_with_numbers = [f\"{i+1}. {reseller}\\n\" for i, reseller in enumerate(reseller_names)]\n",
    "            seller_data.append([asin, seller_name, availability_status, num_other_sellers, \"\".join(resellers_with_numbers)])\n",
    "        else:\n",
    "            seller_data.append([asin, seller_name, availability_status, num_other_sellers,resellers_with_numbers:='No Reseller'])\n",
    "\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return seller_data\n",
    "\n",
    "def read_asins_from_csv(filename):\n",
    "    asins = []\n",
    "    with open(filename, 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            asins.extend(row)\n",
    "    return asins\n",
    "\n",
    "def write_seller_names_and_availability_to_csv(filename, seller_data):\n",
    "    with open(filename, 'w', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow(['ASIN', 'Seller Name', 'Availability_of_Product', 'Number_of_resellers', 'Reseller_names'])\n",
    "        for data in seller_data:\n",
    "            csv_writer.writerow(data)\n",
    "\n",
    "# Example usage\n",
    "input_csv = '/Users/asifa/Desktop/Asifa/buyboxMonitor/input2.csv'\n",
    "output_csv = '/Users/asifa/Desktop/Asifa/buyboxMonitor/Output2.csv'\n",
    "\n",
    "asins = read_asins_from_csv(input_csv)\n",
    "seller_data = get_seller_names_and_availability(asins)\n",
    "write_seller_names_and_availability_to_csv(output_csv, seller_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODIFYING PREVIOUS CODE TO ADD PRICES OF THE RESELERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Function for getting the number of resellers and their names\n",
    "def get_other_sellers_and_name(asin):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    offerlist_url = f\"https://www.amazon.it/dp/{asin}/ref=olp-opf-redir?aod=1&ie=UTF8&condition=NEW&th=1\"\n",
    "    driver.get(offerlist_url)\n",
    "\n",
    "    html = driver.page_source\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    input_element = soup.find('input', {'id': 'aod-total-offer-count'})\n",
    "    if input_element is not None:\n",
    "        num_other_sellers = int(input_element.get('value', '0'))\n",
    "    else:\n",
    "        num_other_sellers = 0\n",
    "\n",
    "    # Find all the reseller names on the page\n",
    "    offer_list_div = soup.find('div', {'id': 'aod-offer-list'})\n",
    "    if offer_list_div:\n",
    "        reseller_data = []\n",
    "        reseller_elements = offer_list_div.find_all(\n",
    "            lambda tag: (tag.name == 'a' and tag.get('aria-label') == 'Apre una nuova pagina') or\n",
    "                        (tag.name == 'span' and tag.get('aria-label') == 'Amazon. Apre una nuova pagina')\n",
    "        )\n",
    "        for reseller in reseller_elements:\n",
    "            reseller_name = reseller.get_text(strip=True)\n",
    "            reseller_data.append(reseller_name)\n",
    "    else:\n",
    "        reseller_data = 'No Resellers'\n",
    "    if offer_list_div:\n",
    "        reseller_price_data = []\n",
    "        # Find all the spans containing prices with class 'a-offscreen' and 'a-price'\n",
    "        price_spans = offer_list_div.find_all('span', class_=['a-price'])\n",
    "        reseller_price_data = [price_span.text.strip() for price_span in price_spans]\n",
    "        \n",
    "    else:\n",
    "        reseller_price_data = 'No Prices'\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    return num_other_sellers, reseller_data, reseller_price_data\n",
    "\n",
    "\n",
    "def get_seller_names_and_availability(asins):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    seller_data = []\n",
    "\n",
    "    for asin in asins:\n",
    "        product_url = f\"https://www.amazon.it/dp/{asin}\"\n",
    "        driver.get(product_url)\n",
    "\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        seller_element = soup.find('a', {'id': 'sellerProfileTriggerId'})\n",
    "        availability_div = soup.find('div', {'id': 'availability'})\n",
    "\n",
    "        if availability_div is not None:\n",
    "            if \"Non disponibile\" in availability_div.get_text():\n",
    "                availability_status = \"Not Available\"\n",
    "                seller_name = \"none\"\n",
    "            else:\n",
    "                availability_status = \"Available\"\n",
    "                if seller_element is not None:\n",
    "                    seller_name = seller_element.get_text(strip=True)\n",
    "                else:\n",
    "                    seller_name = \"Amazon\"\n",
    "        else:\n",
    "            availability_status = \"Product page not found\"\n",
    "            seller_name = \"none\"\n",
    "\n",
    "        num_other_sellers, reseller_names, reseller_price_data = get_other_sellers_and_name(asin)\n",
    "        if num_other_sellers > 0:\n",
    "            resellers_with_numbers = [f\"{i+1}. {reseller} - Price: {price}\\n\" for i, (reseller, price) in enumerate(zip(reseller_names, reseller_price_data))]\n",
    "            seller_data.append([asin, seller_name, availability_status, num_other_sellers, \"\".join(resellers_with_numbers)])\n",
    "        else:\n",
    "            seller_data.append([asin, seller_name, availability_status, num_other_sellers, 'No Reseller', 'No Prices'])\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return seller_data\n",
    "\n",
    "def read_asins_from_csv(filename):\n",
    "    asins = []\n",
    "    with open(filename, 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            asins.extend(row)\n",
    "    return asins\n",
    "\n",
    "def write_seller_names_and_availability_to_csv(filename, seller_data):\n",
    "    with open(filename, 'w', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow(['ASIN', 'Seller Name', 'Availability_of_Product', 'Number_of_resellers', 'Reseller_names','reseller_price'])\n",
    "        for data in seller_data:\n",
    "            csv_writer.writerow(data)\n",
    "\n",
    "# Example usage\n",
    "input_csv = '/Users/asifa/Desktop/Asifa/buyboxMonitor/input2.csv'\n",
    "output_csv = '/Users/asifa/Desktop/Asifa/buyboxMonitor/Output2.csv'\n",
    "\n",
    "asins = read_asins_from_csv(input_csv)\n",
    "seller_data = get_seller_names_and_availability(asins)\n",
    "write_seller_names_and_availability_to_csv(output_csv, seller_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
